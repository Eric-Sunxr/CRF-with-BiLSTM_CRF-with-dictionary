# CRF-with-BiLSTM_CRF-with-dictionary
It's a repository about CRF task using BiLSTM(tensorflow)+Attention and Dictionary matching. I think it's easy but efficient. It's a wonderful Entry-level NLP linkages.
#
# 自然语言处理

# NER

# 任务实验报告


# 神经网络方法

## 标签类型：

命名实体识别任务其本质上依旧是一个分类型任务。最后输出的结果是每一个字所代表的实体类型以及实体的位置。我们本次所使用的实体类型有以下13种：

| **LABEL** | **MEANING** | **LABEL** | **MEANING** |
| --- | --- | --- | --- |
| **O** | **无类型** | **B-OPERATION** | **手术** |
| **B-DISEASE** | **疾病和诊断** | **I-OPERATION** | **手术** |
| **I-DISEASE** | **疾病和诊断** | **B-PIC** | **影像检查** |
| **B-BODY** | **解剖部位** | **I-PIC** | **影像检查** |
| **I-BODY** | **解剖部位** | **B-LAB** | **实验室检验** |
| **B-MEDICINE** | **药物** | **I-LAB** | **实验室检验** |
| **I-MEDICINE** | **药物** |
 |
 |

## 网络结构

我们使用的神经网络如下图所示，

![](RackMultipart20210524-4-8r97t_html_992919312f8587c1.png)

首先，在第一层，目的是将每个字符表示从一个one-hot编码转换成字符嵌入，在这一段代码中，先随机初始化嵌入矩阵然后直接代入。在这里，并没有考虑使用word2vec等预训练好的词向量，原因是由于医学领域词汇的特殊性和冷门性，我们觉得使用包含上下文语义的预训练词向量可能会干扰神经网络对于医疗词汇整体的判断。因此使用随机初始化的方式避免此干扰。

其次，我们使用了一层双向LSTM层，LSTM神经网络可以有效提取上下文特征，通过深度学习的方法可以得到针对于医疗领域的特殊模型。

最后，使用一层tensorflow自带的CRF层进行一些语义规则上的修正。如果我们使用Softmax层来标记，我们可能会得到仅仅凭借概率得到的标签序列，因为Softmax层只能分别标记每个位置，但是不能知道前后关联词语之前的特征。例如，我们知道I-PIC不能跟上B-PIC，但Softmax不知道。与Softmax相比，CRF层可以使用句子级标签信息并对两个不同标签的转换行为建模。很好的避免了一些基于规则而产生的误差性错误。

## 代码运行流程

![](RackMultipart20210524-4-8r97t_html_ce8fa14cbf327129.png)

# CRF+词典匹配法

## 方法描述

在前面我们介绍了深度学习的方法，下面我们介绍CRF+词典匹配的方法。虽然目前主流的命名实体识别方法是深度学习，但是我们认为有必要尝试最原始的方法，也就是词典匹配。正所谓有了坦克大炮，也不能忘记小米步枪。

我们使用CRF+词典匹配方法的灵感来源于自然语言处理实践课第一节课宿师哥所教授我们的分词匹配方法，因为医疗文本词汇本身具有生僻性，出现重复的情况较少，而且易于扩写，所以我们认为CRF+词典匹配的方法是可行的。

## 词典构建

我们在GitHub中找到了一个医疗文本语料库，包含medicine、operation、disease、body等标签类型的内容。然后我们对语料库进行了去重、排序等处理，并去除长度超过50的词汇，最终得到我们词典匹配中使用的dictionary。

## 工作流程

基 ![](RackMultipart20210524-4-8r97t_html_6627f8a9d38b231e.jpg)
 于CRF+词典匹配医疗文本命名实体识别总体流程如下图所示：

如图所示，我们对整个实验的流程做简单的陈述：

第一步：首先将两份json文件进行数据预处理，按4:1的比例分为训练语料和测试语料；将训练语料进行标注转换后，利用CRF模型对转换后的语料进行训练，最终生成模型参数。

第二步：利用分词器对测试语料进行分词和词性标注，并利用上一步得到的CRF模型进行医疗文本命名实体的识别。最终将词形和词性标注序列转换为本文定义的标注集序列。

第三步：在上一步识别的基础上，使用词典匹配的方法进行二次识别。

## 词典匹配流程：

下面介绍一下我们使用的词典匹配算法的具体流程（如下图）：

![](RackMultipart20210524-4-8r97t_html_a512dee9c915eff9.png)

首先，将词典中的词和标签分别输入两个列表，也将CRF结果中的字和对应标签输入两个列表中。

而后对CRF结果中的每个字进行遍历，从这个字开始，依次取该字后的m个字组成一个词（包括这个字自己，m（0~词典中最长词长度个字-1）），将该词与词典中的每个词比较，如果相同，就将每个字标签对应为词典中该词对应的标签（对标签DISEASE、MEDICINE、OPERATION、PIC进行（BODY与OPERATION会有重复）），如果匹配成功且词长度大于1，那么要从当前字之后的m+1个字开始进行下一轮。

对于列表中第83625之后的字，m的最大值为字的序数减去83625，这是由于字的总个数为83681，而词典中最长词长度为56，对于最后的55个字，必须保证向后查找字组成词时不越界。

## 实验注意点

使用词典修正需要的时间较长，需要运行超过2个小时。这主要是由于词典中的最大词长度较长。长度如果超过50，导致对每个字需要向后查找的次数较多。而修正后的结果相比仅仅使用CRF的结果，准确率稍低而召回率、F1值更高， **这是由于一些词典中匹配出的标签在原本的数据集的正确结果里未被标注** 。因此我们觉得词典匹配方法是可以用来扩展预料集的。

# 实验结果

我们的实验使用了 **5**** 交叉验证**之后，得到结果如下表所示：

| **Types** | **Precision** | **Recall** | **F1-score** |
| --- | --- | --- | --- |
| **Baseline**** （ ****CRF**** ）** | 79.94% | 74.63% | 77.19% |
| **BiLSTM+CRF** | 90.08% | 88.98% | 89.48% |
| **Dictionary-Match** | 87.71% | 90.98% | 88.42% |
| **BiLSTM+CRF+Dictionary** | 87.05% | 91.33% | 88.29% |

**\***** 以上数据均基于 ****5-**** 交叉验证**

通过结果我们可以看到字典的方法可以很好地增加数据的召回率，而使用BiLSTM结合CRF的方法却能保证准确率。

![](RackMultipart20210524-4-8r97t_html_f8aaa488af7ece8.gif)
